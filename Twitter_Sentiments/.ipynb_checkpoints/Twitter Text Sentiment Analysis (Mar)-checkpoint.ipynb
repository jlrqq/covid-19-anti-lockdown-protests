{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Text Sentiment Analysis for Twitter Posts</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective:\n",
    "- Find out the different sentiment levels (negative, neutral, positive) among the posts and generate word clouds to discover key motivations / beliefs driving the sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install seaborn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import plotly.express as px\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import seaborn as sns\n",
    "import matplotlib.style as style\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/cjhutto/vaderSentiment#about-the-scoring\n",
    "# positive sentiment: compound score >= 0.05\n",
    "# neutral sentiment: (compound score > -0.05) and (compound score < 0.05)\n",
    "# negative sentiment: compound score <= -0.05\n",
    "\n",
    "def sentiment_analyzer_score(sentence):\n",
    "    score = analyser.polarity_scores(sentence)\n",
    "    return score['compound']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Twitter Data from Local CSV\n",
    "\n",
    "tweets = pd.read_csv('../Twitter_Data/Twitter_Mar_5000.csv', index_col=0)\n",
    "\n",
    "print(tweets.shape)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Twitter Data from S3 \n",
    "\n",
    "# import pandas as pd\n",
    "# import boto3\n",
    "# import io\n",
    "\n",
    "# AWS_ACCESS_KEY_ID = \"*\"\n",
    "# AWS_SECRET_ACCESS_KEY = \"*\"\n",
    "# bucket = \"is434-last-sem-best-sem\"\n",
    "# file_name = \"data-lake/tweeter_data.csv\"\n",
    "\n",
    "# # Create connection to S3 and all buckets within S3\n",
    "# s3 = boto3.client(\n",
    "#     's3',\n",
    "#     aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "#     aws_secret_access_key=AWS_SECRET_ACCESS_KEY,\n",
    "# )\n",
    "\n",
    "# # Get object and file (key) from bucket\n",
    "# obj = s3.get_object(Bucket= bucket, Key= file_name) \n",
    "\n",
    "# tweets = pd.read_csv(io.BytesIO(obj['Body'].read()))\n",
    "# tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Text from DataFrame into a List\n",
    "\n",
    "tweet_text_list = tweets['Text'].tolist()\n",
    "tweet_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean Text Function\n",
    "\n",
    "def clean_tweet(comments):\n",
    "\n",
    "    test_sentences = sent_tokenize(comments)\n",
    "    test_sentences\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    test_words = tokenizer.tokenize(comments)\n",
    "    test_words_lower = list(map(lambda x: x.lower(), test_words)) \n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "    # print(stop_words)\n",
    "    stop_words2 = ['co', 'covid', 'covid19', 'coronavirus', 'lockdown', 'covid19 lockdown', '&amp', 'amp']\n",
    "\n",
    "    filtered_test_words = []\n",
    "\n",
    "    for w in test_words_lower:\n",
    "        if w not in stop_words and w not in stop_words2:\n",
    "            filtered_test_words.append(w)\n",
    "\n",
    "    porter_stemer = PorterStemmer()\n",
    "\n",
    "    stemed_filter_test_words = []\n",
    "    for i in filtered_test_words:\n",
    "        stemed_filter_test_words.append(porter_stemer.stem(i))\n",
    "\n",
    "    join_words = \" \".join([x for x in stemed_filter_test_words])\n",
    "\n",
    "    return join_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract processed text\n",
    "\n",
    "processed_text = [clean_tweet(tw) for tw in tweet_text_list]\n",
    "processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add processed text into the DataFrame\n",
    "\n",
    "tweets['processed_text'] = processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract processed tweets column\n",
    "\n",
    "tweets_list = tweets['processed_text'].tolist()\n",
    "tweets_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a list of sentiment scores for tweets\n",
    "\n",
    "sentiment_score_list = []\n",
    "for sentence in tweets_list:\n",
    "    sentiment_score = sentiment_analyzer_score(str(sentence))\n",
    "    sentiment_score_list.append(sentiment_score)\n",
    "\n",
    "sentiment_score_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add 'sentiment_score' column\n",
    "\n",
    "tweets['sentiment_score'] = sentiment_score_list\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label sentiments (positive, negative, neutral) based on sentiment_score for each tweet\n",
    "\n",
    "tweets['sentiment_score'].apply(lambda x: float(x))\n",
    "tweets['sentiment_label'] = 'NA'\n",
    "tweets.loc[tweets.sentiment_score == 0, 'sentiment_label'] = 'neutral'\n",
    "tweets.loc[tweets.sentiment_score < 0, 'sentiment_label'] = 'negative'\n",
    "tweets.loc[tweets.sentiment_score > 0, 'sentiment_label'] = 'positive'\n",
    "\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get number of tweets for each sentiment\n",
    "\n",
    "tweets_per_sentiment = tweets.groupby(['sentiment_label']).size().reset_index(name='num_posts')\n",
    "tweets_per_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_per_sentiment['percentage_of_total'] = tweets_per_sentiment['num_posts'].apply(lambda x: round(x / tweets.shape[0], 2) * 100)\n",
    "tweets_per_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for tweets with 0.0 sentiments\n",
    "\n",
    "unwanted_index = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve tweets with 0.0 sentiments\n",
    "\n",
    "for index, row in tweets.iterrows():\n",
    "    if row['sentiment_score'] == 0.0:\n",
    "        unwanted_index.append(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of tweets with 0.0 sentiments\n",
    "\n",
    "len(unwanted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final tweets DataFrame\n",
    "\n",
    "final_tweets = tweets.drop(unwanted_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview final tweets DataFrame\n",
    "\n",
    "final_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview desc stats of final tweets DataFrame\n",
    "\n",
    "final_tweets.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res = pd.Series(final_tweets['sentiment_score'], name=\"sentiment_score\")\n",
    "# print(res)\n",
    "# plt = sns.distplot(res)\n",
    "# plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise percentage of posts with each sentiment\n",
    "\n",
    "#### Plot settings ####\n",
    "style.use('seaborn-poster') # sets the size of the charts\n",
    "style.use('ggplot')\n",
    "matplotlib.rcParams['font.family'] = \"DejaVu Sans\"\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "sns.set_context('paper')\n",
    "\n",
    "cols = ['red' if label == 'negative' else ('green' if label == 'positive' else 'gray') for label in tweets_per_sentiment['sentiment_label']]\n",
    "ax = sns.barplot(x=\"sentiment_label\",\n",
    "                 y=\"percentage_of_total\",\n",
    "                 data=tweets_per_sentiment,\n",
    "                 palette=cols\n",
    "                )\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(format(p.get_height(), '.1f'), (p.get_x() + p.get_width() / 2., p.get_height()), ha = 'center', va = 'center', xytext = (0, 10), textcoords = 'offset points')\n",
    "\n",
    "ax.set(xlabel='Sentiment', ylabel='Percentage of Covid-19 Lockdown Tweets')\n",
    "\n",
    "plt.savefig('../Twitter_Output/Twitter_Mar_SentimentChart.png', dpi=400, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word Cloud Function\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def generate_word_cloud(dataframe, category):\n",
    "    comment_words = ''\n",
    "    processed_text = dataframe['processed_text']\n",
    "    \n",
    "    # iterate through list\n",
    "    for tweet_text in processed_text:\n",
    "        # split the text into tokens\n",
    "        tokens = tweet_text.split()\n",
    "        # Append tokens to string comment_words\n",
    "        comment_words += \" \".join(tokens)+\" \"\n",
    "\n",
    "    # make a word cloud\n",
    "    wordcloud = WordCloud(width = 800, height = 800,\n",
    "                    background_color ='black', colormap='rainbow',\n",
    "                    #stopwords = stopwords,\n",
    "                    min_font_size = 10).generate(comment_words)\n",
    "\n",
    "    # plot the word cloud image                      \n",
    "    plt.figure(figsize = (8, 8), facecolor = None)\n",
    "    plt.imshow(wordcloud)\n",
    "    plt.axis(\"off\")\n",
    "    plt.tight_layout(pad = 0)\n",
    "\n",
    "    plt.show()\n",
    "    wordcloud.to_file(f'../Twitter_Output/Twitter_Mar_Wordcloud_{category}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All Sentiment Word Cloud\n",
    "\n",
    "generate_word_cloud(tweets, 'all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Negative Sentiment DataFrame\n",
    "\n",
    "negative = tweets[tweets['sentiment_label'] == 'negative']\n",
    "generate_word_cloud(negative, 'negative')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neutral Sentiment DataFrame\n",
    "\n",
    "neutral = tweets[tweets['sentiment_label'] == 'neutral']\n",
    "generate_word_cloud(neutral, 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive Sentiment DataFrame\n",
    "\n",
    "positive = tweets[tweets['sentiment_label'] == 'positive']\n",
    "generate_word_cloud(positive, 'positive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to a CSV\n",
    "\n",
    "# path = \"./Twitter_Sentiments/\"\n",
    "# if not os.path.exists(path):\n",
    "#         os.makedirs(path)\n",
    "\n",
    "tweets.to_csv('./Twitter_Mar_Sentiments.csv') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
