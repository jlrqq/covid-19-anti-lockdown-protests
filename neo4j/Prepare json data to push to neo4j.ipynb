{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "278dce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe520a2",
   "metadata": {},
   "source": [
    "### Tweets sentiment & topic_modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2675c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar = pd.read_csv('../Twitter_Sentiments/Twitter_Jan_Mar_Sentiments.csv')\n",
    "Mar = pd.read_csv('../Twitter_Sentiments/Twitter_Mar_Sentiments.csv')\n",
    "May_Nov = pd.read_csv('../Twitter_Sentiments/Twitter_May_Nov_Sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70904fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar_top = pd.read_csv('../Twitter_Sentiments_SpecificEmotions/Twitter_Jan_Mar_5000.csv')\n",
    "Mar_top = pd.read_csv('../Twitter_Sentiments_SpecificEmotions/Twitter_Mar_5000.csv')\n",
    "May_Nov_top = pd.read_csv('../Twitter_Sentiments_SpecificEmotions/Twitter_May_Nov_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "241dd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar_tm = pd.read_csv('../Twitter_Topic_Modelling/output/jan_mar.csv')\n",
    "Mar_tm = pd.read_csv('../Twitter_Topic_Modelling/output/mar.csv')\n",
    "May_Nov_tm = pd.read_csv('../Twitter_Topic_Modelling/output/may_nov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6c84950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar.drop(columns=['processed_text','Coordinates','Place'], inplace=True)\n",
    "Mar.drop(columns=['processed_text','Coordinates','Place'], inplace=True)\n",
    "May_Nov.drop(columns=['processed_text','Coordinates','Place'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd38f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar[['rt_username','tag_usernames']] = pd.DataFrame([[np.nan, '']], index=Jan_Mar.index)\n",
    "Mar[['rt_username','tag_usernames']] = pd.DataFrame([[np.nan, '']], index=Mar.index)\n",
    "May_Nov[['rt_username','tag_usernames']] = pd.DataFrame([[np.nan, '']], index=May_Nov.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0e3c27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in Jan_Mar.iterrows():\n",
    "    # retweets\n",
    "    regex_rt = r'RT[ ]*(@[A-Za-z0-9_]+)'\n",
    "    match = re.search(regex_rt, row['Text'])\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        Jan_Mar.loc[i, 'rt_username'] = sub_string[4:]\n",
    "    else:\n",
    "        # tags\n",
    "        regex_tags = r'@[A-Za-z0-9_]+'\n",
    "        matches = re.findall(regex_tags, row['Text'])\n",
    "        if matches:\n",
    "            Jan_Mar.at[i, 'tag_usernames'] = [s[1:] for s in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "699087db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in Mar.iterrows():\n",
    "    # retweets\n",
    "    regex_rt = r'RT[ ]*(@[A-Za-z0-9_]+)'\n",
    "    match = re.search(regex_rt, row['Text'])\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        Mar.loc[i, 'rt_username'] = sub_string[4:]\n",
    "    else:\n",
    "        # tags\n",
    "        regex_tags = r'@[A-Za-z0-9_]+'\n",
    "        matches = re.findall(regex_tags, row['Text'])\n",
    "        if matches:\n",
    "            Mar.at[i, 'tag_usernames'] = [s[1:] for s in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e2a5d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in May_Nov.iterrows():\n",
    "    # retweets\n",
    "    regex_rt = r'RT[ ]*(@[A-Za-z0-9_]+)'\n",
    "    match = re.search(regex_rt, row['Text'])\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        May_Nov.loc[i, 'rt_username'] = sub_string[4:]\n",
    "    else:\n",
    "        # tags\n",
    "        regex_tags = r'@[A-Za-z0-9_]+'\n",
    "        matches = re.findall(regex_tags, row['Text'])\n",
    "        if matches:\n",
    "            May_Nov.at[i, 'tag_usernames'] = [s[1:] for s in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d0df2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar['tag_usernames'] = Jan_Mar['tag_usernames'].replace('', np.nan)\n",
    "Mar['tag_usernames'] = Mar['tag_usernames'].replace('', np.nan)\n",
    "May_Nov['tag_usernames'] = May_Nov['tag_usernames'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "29693f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = Jan_Mar_top[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "Mar[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = Mar_top[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "May_Nov[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = May_Nov_top[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "178f1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = Jan_Mar_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]\n",
    "Mar[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = Mar_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]\n",
    "May_Nov[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = May_Nov_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29293a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>rt_username</th>\n",
       "      <th>tag_usernames</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>top_emotion</th>\n",
       "      <th>top_emotion_score</th>\n",
       "      <th>second_emotion</th>\n",
       "      <th>second_emotion_score</th>\n",
       "      <th>third_emotion</th>\n",
       "      <th>third_emotion_score</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1333198979224399873</td>\n",
       "      <td>@nspector4 @keithbaldrey France initiated dras...</td>\n",
       "      <td>Teelin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nspector4, keithbaldrey]</td>\n",
       "      <td>2020-11-29 23:59:40+00:00</td>\n",
       "      <td>realization</td>\n",
       "      <td>0.995364</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>right, catch, people, need, case, go, due, say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet Id                                               Text  \\\n",
       "0  1333198979224399873  @nspector4 @keithbaldrey France initiated dras...   \n",
       "\n",
       "  Username  sentiment_score sentiment_label rt_username  \\\n",
       "0   Teelin              0.0         neutral         NaN   \n",
       "\n",
       "               tag_usernames                   Datetime  top_emotion  \\\n",
       "0  [nspector4, keithbaldrey]  2020-11-29 23:59:40+00:00  realization   \n",
       "\n",
       "   top_emotion_score second_emotion  second_emotion_score third_emotion  \\\n",
       "0           0.995364       approval              0.002405       neutral   \n",
       "\n",
       "   third_emotion_score  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0.000781             2.0              0.3965   \n",
       "\n",
       "                                            Keywords  \n",
       "0  right, catch, people, need, case, go, due, say...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "May_Nov.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff18260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dfs = [Jan_Mar, Mar, May_Nov]\n",
    "tweet = pd.concat(tweet_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "529df2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.columns = (tweet.columns.str.replace(' ', '_', regex=True).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "61d3c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11337 entries, 0 to 11336\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   tweet_id              11337 non-null  int64  \n",
      " 1   text                  11337 non-null  object \n",
      " 2   username              11337 non-null  object \n",
      " 3   sentiment_score       11337 non-null  float64\n",
      " 4   sentiment_label       11337 non-null  object \n",
      " 5   rt_username           23 non-null     object \n",
      " 6   tag_usernames         3617 non-null   object \n",
      " 7   datetime              11337 non-null  object \n",
      " 8   top_emotion           11337 non-null  object \n",
      " 9   top_emotion_score     11337 non-null  float64\n",
      " 10  second_emotion        11337 non-null  object \n",
      " 11  second_emotion_score  11337 non-null  float64\n",
      " 12  third_emotion         11337 non-null  object \n",
      " 13  third_emotion_score   11337 non-null  float64\n",
      " 14  dominant_topic        11337 non-null  float64\n",
      " 15  topic_perc_contrib    11337 non-null  float64\n",
      " 16  keywords              11337 non-null  object \n",
      "dtypes: float64(6), int64(1), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15150d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May_Nov[\"Place\"][May_Nov[\"Place\"].isnull() == False][31]\n",
    "# May_Nov[May_Nov[\"Place\"].isnull() == False]['Place'] = May_Nov[May_Nov[\"Place\"].isnull() == False]['Place'].str.replace({'Place': '', '(': '{', ')': '}', '=': ':'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c185ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.to_json('./tweets_upload.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c21e7",
   "metadata": {},
   "source": [
    "### Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3df342c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('../Reddit_Sentiments/antilockdown_sentiments.csv')\n",
    "r2 = pd.read_csv('../Reddit_Sentiments/corona_sentiments.csv')\n",
    "r3 = pd.read_csv('../Reddit_Sentiments/covid19_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb27fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_top = pd.read_csv('../Reddit_Sentiments_SpecificEmotions/anti_lockdown_comments.csv')\n",
    "r2_top = pd.read_csv('../Reddit_Sentiments_SpecificEmotions/corona_lockdown_comments.csv')\n",
    "r3_top = pd.read_csv('../Reddit_Sentiments_SpecificEmotions/covid19_lockdown_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b383b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_tm = pd.read_csv('../Reddit_Topic_Modelling/output/reddit_overall_dominant_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc723a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.drop(columns=['Unnamed: 0.1','Unnamed: 0','cluster'], inplace=True)\n",
    "r2.drop(columns=['Unnamed: 0.1','Unnamed: 0','cluster'], inplace=True)\n",
    "r3.drop(columns=['Unnamed: 0.1','Unnamed: 0','cluster'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb9443b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = r1[r1.comment != \"remov\"]\n",
    "r2 = r2[r2.comment != \"remov\"]\n",
    "r3 = r3[r3.comment != \"remov\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "072f7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = r1_top[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "r2[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = r2_top[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "r3[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = r3_top[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1e4ebf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11576</th>\n",
       "      <td>11576</td>\n",
       "      <td>11576</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3971</td>\n",
       "      <td>people, time, think, make, work, go, much, tes...</td>\n",
       "      <td>['economic', 'analysis', 'economic', 'decision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>11577</td>\n",
       "      <td>11577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>case, death, country, need, even, spread, vacc...</td>\n",
       "      <td>['sub', 'seem', 'attract', 'poster', 'late', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>11578</td>\n",
       "      <td>11578</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>know, get, good, seem, month, place, report, m...</td>\n",
       "      <td>['true', 'sub', 'community', 'hover', 'certain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>11579</td>\n",
       "      <td>11579</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>people, time, think, make, work, go, much, tes...</td>\n",
       "      <td>['fortunately', 'model', 'ihme', 'capable', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>11580</td>\n",
       "      <td>11580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>case, death, country, need, even, spread, vacc...</td>\n",
       "      <td>['fortunately', 'model', 'ihme', 'capable', 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "11576       11576        11576             2.0              0.3971   \n",
       "11577       11577        11577             0.0              0.3321   \n",
       "11578       11578        11578             3.0              0.4027   \n",
       "11579       11579        11579             2.0              0.3312   \n",
       "11580       11580        11580             0.0              0.3245   \n",
       "\n",
       "                                                Keywords  \\\n",
       "11576  people, time, think, make, work, go, much, tes...   \n",
       "11577  case, death, country, need, even, spread, vacc...   \n",
       "11578  know, get, good, seem, month, place, report, m...   \n",
       "11579  people, time, think, make, work, go, much, tes...   \n",
       "11580  case, death, country, need, even, spread, vacc...   \n",
       "\n",
       "                                                    Text  \n",
       "11576  ['economic', 'analysis', 'economic', 'decision...  \n",
       "11577  ['sub', 'seem', 'attract', 'poster', 'late', '...  \n",
       "11578  ['true', 'sub', 'community', 'hover', 'certain...  \n",
       "11579  ['fortunately', 'model', 'ihme', 'capable', 'm...  \n",
       "11580  ['fortunately', 'model', 'ihme', 'capable', 'm...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_tm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74fc80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dfs = [r1, r2, r3]\n",
    "reddit = pd.concat(reddit_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01971820",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = overall_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f274c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.columns = (reddit.columns.str.replace(' ', '_', regex=True).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71422a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11581 entries, 0 to 11580\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          11581 non-null  object \n",
      " 1   author                      11581 non-null  object \n",
      " 2   title                       11581 non-null  object \n",
      " 3   score                       11581 non-null  int64  \n",
      " 4   comms_num                   11581 non-null  int64  \n",
      " 5   created                     11581 non-null  float64\n",
      " 6   timestamp                   11581 non-null  object \n",
      " 7   commenter                   9901 non-null   object \n",
      " 8   comment                     11557 non-null  object \n",
      " 9   top_lvl                     11581 non-null  int64  \n",
      " 10  sentiment_polarity          11581 non-null  float64\n",
      " 11  sentiment_polarity_summary  11581 non-null  object \n",
      " 12  top_emotion                 11581 non-null  object \n",
      " 13  top_emotion_score           11581 non-null  float64\n",
      " 14  second_emotion              11581 non-null  object \n",
      " 15  second_emotion_score        11581 non-null  float64\n",
      " 16  third_emotion               11581 non-null  object \n",
      " 17  third_emotion_score         11581 non-null  float64\n",
      " 18  dominant_topic              11581 non-null  float64\n",
      " 19  topic_perc_contrib          11581 non-null  float64\n",
      " 20  keywords                    11581 non-null  object \n",
      "dtypes: float64(7), int64(3), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9355b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.to_json('./reddits_upload.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bbb752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
