{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "278dce36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe520a2",
   "metadata": {},
   "source": [
    "### Tweets sentiment & topic_modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2675c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar = pd.read_csv('../Twitter_Sentiments/Twitter_Jan_Mar_Sentiments.csv')\n",
    "Mar = pd.read_csv('../Twitter_Sentiments/Twitter_Mar_Sentiments.csv')\n",
    "May_Nov = pd.read_csv('../Twitter_Sentiments/Twitter_May_Nov_Sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "70904fae",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar_top = pd.read_csv('../Twitter_Sentiments_SpecificEmotions/Twitter_Jan_Mar_5000.csv')\n",
    "Mar_top = pd.read_csv('../Twitter_Sentiments_SpecificEmotions/Twitter_Mar_5000.csv')\n",
    "May_Nov_top = pd.read_csv('../Twitter_Sentiments_SpecificEmotions/Twitter_May_Nov_5000.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "241dd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar_tm = pd.read_csv('../Twitter_Topic_Modelling/output/jan_mar.csv')\n",
    "Mar_tm = pd.read_csv('../Twitter_Topic_Modelling/output/mar.csv')\n",
    "May_Nov_tm = pd.read_csv('../Twitter_Topic_Modelling/output/may_nov.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c6c84950",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar.drop(columns=['processed_text','Coordinates','Place'], inplace=True)\n",
    "Mar.drop(columns=['processed_text','Coordinates','Place'], inplace=True)\n",
    "May_Nov.drop(columns=['processed_text','Coordinates','Place'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd38f201",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar[['rt_username','tag_usernames']] = pd.DataFrame([[np.nan, '']], index=Jan_Mar.index)\n",
    "Mar[['rt_username','tag_usernames']] = pd.DataFrame([[np.nan, '']], index=Mar.index)\n",
    "May_Nov[['rt_username','tag_usernames']] = pd.DataFrame([[np.nan, '']], index=May_Nov.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0e3c27b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in Jan_Mar.iterrows():\n",
    "    # retweets\n",
    "    regex_rt = r'RT[ ]*(@[A-Za-z0-9_]+)'\n",
    "    match = re.search(regex_rt, row['Text'])\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        Jan_Mar.loc[i, 'rt_username'] = sub_string[4:]\n",
    "    else:\n",
    "        # tags\n",
    "        regex_tags = r'@[A-Za-z0-9_]+'\n",
    "        matches = re.findall(regex_tags, row['Text'])\n",
    "        if matches:\n",
    "            Jan_Mar.at[i, 'tag_usernames'] = [s[1:] for s in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "699087db",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in Mar.iterrows():\n",
    "    # retweets\n",
    "    regex_rt = r'RT[ ]*(@[A-Za-z0-9_]+)'\n",
    "    match = re.search(regex_rt, row['Text'])\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        Mar.loc[i, 'rt_username'] = sub_string[4:]\n",
    "    else:\n",
    "        # tags\n",
    "        regex_tags = r'@[A-Za-z0-9_]+'\n",
    "        matches = re.findall(regex_tags, row['Text'])\n",
    "        if matches:\n",
    "            Mar.at[i, 'tag_usernames'] = [s[1:] for s in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2a5d1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, row in May_Nov.iterrows():\n",
    "    # retweets\n",
    "    regex_rt = r'RT[ ]*(@[A-Za-z0-9_]+)'\n",
    "    match = re.search(regex_rt, row['Text'])\n",
    "    if match:\n",
    "        sub_string = match.group()\n",
    "        May_Nov.loc[i, 'rt_username'] = sub_string[4:]\n",
    "    else:\n",
    "        # tags\n",
    "        regex_tags = r'@[A-Za-z0-9_]+'\n",
    "        matches = re.findall(regex_tags, row['Text'])\n",
    "        if matches:\n",
    "            May_Nov.at[i, 'tag_usernames'] = [s[1:] for s in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0df2ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar['tag_usernames'] = Jan_Mar['tag_usernames'].replace('', np.nan)\n",
    "Mar['tag_usernames'] = Mar['tag_usernames'].replace('', np.nan)\n",
    "May_Nov['tag_usernames'] = May_Nov['tag_usernames'].replace('', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3482aaab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5001 entries, 0 to 5000\n",
      "Data columns (total 6 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Unnamed: 0          5001 non-null   int64  \n",
      " 1   Document_No         5001 non-null   int64  \n",
      " 2   Dominant_Topic      5001 non-null   float64\n",
      " 3   Topic_Perc_Contrib  5001 non-null   float64\n",
      " 4   Keywords            5001 non-null   object \n",
      " 5   Text                5001 non-null   object \n",
      "dtypes: float64(2), int64(2), object(2)\n",
      "memory usage: 234.5+ KB\n"
     ]
    }
   ],
   "source": [
    "May_Nov_tm.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc33e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "29693f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = Jan_Mar_top[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "Mar[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = Mar_top[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "May_Nov[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = May_Nov_top[['Datetime','top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "178f1b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Jan_Mar[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = Jan_Mar_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]\n",
    "Mar[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = Mar_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]\n",
    "May_Nov[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = May_Nov_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "29293a32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweet Id</th>\n",
       "      <th>Text</th>\n",
       "      <th>Username</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>sentiment_label</th>\n",
       "      <th>rt_username</th>\n",
       "      <th>tag_usernames</th>\n",
       "      <th>Datetime</th>\n",
       "      <th>top_emotion</th>\n",
       "      <th>top_emotion_score</th>\n",
       "      <th>second_emotion</th>\n",
       "      <th>second_emotion_score</th>\n",
       "      <th>third_emotion</th>\n",
       "      <th>third_emotion_score</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1333198979224399873</td>\n",
       "      <td>@nspector4 @keithbaldrey France initiated dras...</td>\n",
       "      <td>Teelin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[nspector4, keithbaldrey]</td>\n",
       "      <td>2020-11-29 23:59:40+00:00</td>\n",
       "      <td>realization</td>\n",
       "      <td>0.995364</td>\n",
       "      <td>approval</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3965</td>\n",
       "      <td>right, catch, people, need, case, go, due, say...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Tweet Id                                               Text  \\\n",
       "0  1333198979224399873  @nspector4 @keithbaldrey France initiated dras...   \n",
       "\n",
       "  Username  sentiment_score sentiment_label rt_username  \\\n",
       "0   Teelin              0.0         neutral         NaN   \n",
       "\n",
       "               tag_usernames                   Datetime  top_emotion  \\\n",
       "0  [nspector4, keithbaldrey]  2020-11-29 23:59:40+00:00  realization   \n",
       "\n",
       "   top_emotion_score second_emotion  second_emotion_score third_emotion  \\\n",
       "0           0.995364       approval              0.002405       neutral   \n",
       "\n",
       "   third_emotion_score  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "0             0.000781             2.0              0.3965   \n",
       "\n",
       "                                            Keywords  \n",
       "0  right, catch, people, need, case, go, due, say...  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "May_Nov.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ff18260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dfs = [Jan_Mar, Mar, May_Nov]\n",
    "tweet = pd.concat(tweet_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "529df2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.columns = (tweet.columns.str.replace(' ', '_', regex=True).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "61d3c964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11337 entries, 0 to 11336\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   datetime              11337 non-null  object \n",
      " 1   tweet_id              11337 non-null  int64  \n",
      " 2   text                  11337 non-null  object \n",
      " 3   username              11337 non-null  object \n",
      " 4   sentiment_score       11337 non-null  float64\n",
      " 5   sentiment_label       11337 non-null  object \n",
      " 6   rt_username           23 non-null     object \n",
      " 7   tag_usernames         3617 non-null   object \n",
      " 8   top_emotion           11337 non-null  object \n",
      " 9   top_emotion_score     11337 non-null  float64\n",
      " 10  second_emotion        11337 non-null  object \n",
      " 11  second_emotion_score  11337 non-null  float64\n",
      " 12  third_emotion         11337 non-null  object \n",
      " 13  third_emotion_score   11337 non-null  float64\n",
      " 14  dominant_topic        11337 non-null  float64\n",
      " 15  topic_perc_contrib    11337 non-null  float64\n",
      " 16  keywords              11337 non-null  object \n",
      "dtypes: float64(6), int64(1), object(10)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "tweet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15150d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# May_Nov[\"Place\"][May_Nov[\"Place\"].isnull() == False][31]\n",
    "# May_Nov[May_Nov[\"Place\"].isnull() == False]['Place'] = May_Nov[May_Nov[\"Place\"].isnull() == False]['Place'].str.replace({'Place': '', '(': '{', ')': '}', '=': ':'}, regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c185ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.to_json('./tweets_upload.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640c21e7",
   "metadata": {},
   "source": [
    "### Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "3df342c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('../Reddit_Sentiments/antilockdown_sentiments.csv')\n",
    "r2 = pd.read_csv('../Reddit_Sentiments/corona_sentiments.csv')\n",
    "r3 = pd.read_csv('../Reddit_Sentiments/covid19_sentiments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fb27fa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1_top = pd.read_csv('../Reddit_Sentiments_SpecificEmotions/anti_lockdown_comments.csv')\n",
    "r2_top = pd.read_csv('../Reddit_Sentiments_SpecificEmotions/corona_lockdown_comments.csv')\n",
    "r3_top = pd.read_csv('../Reddit_Sentiments_SpecificEmotions/covid19_lockdown_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "b383b799",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_tm = pd.read_csv('../Reddit_Topic_Modelling/output/reddit_overall_dominant_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "fc723a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1.drop(columns=['Unnamed: 0.1','Unnamed: 0','cluster'], inplace=True)\n",
    "r2.drop(columns=['Unnamed: 0.1','Unnamed: 0','cluster'], inplace=True)\n",
    "r3.drop(columns=['Unnamed: 0.1','Unnamed: 0','cluster'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "eb9443b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = r1[r1.comment != \"remov\"]\n",
    "r2 = r2[r2.comment != \"remov\"]\n",
    "r3 = r3[r3.comment != \"remov\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "072f7bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = r1_top[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "r2[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = r2_top[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]\n",
    "r3[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']] = r3_top[['top_emotion','top_emotion_score','second_emotion','second_emotion_score', 'third_emotion','third_emotion_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1e4ebf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Document_No</th>\n",
       "      <th>Dominant_Topic</th>\n",
       "      <th>Topic_Perc_Contrib</th>\n",
       "      <th>Keywords</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11576</th>\n",
       "      <td>11576</td>\n",
       "      <td>11576</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3971</td>\n",
       "      <td>people, time, think, make, work, go, much, tes...</td>\n",
       "      <td>['economic', 'analysis', 'economic', 'decision...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11577</th>\n",
       "      <td>11577</td>\n",
       "      <td>11577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>case, death, country, need, even, spread, vacc...</td>\n",
       "      <td>['sub', 'seem', 'attract', 'poster', 'late', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11578</th>\n",
       "      <td>11578</td>\n",
       "      <td>11578</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.4027</td>\n",
       "      <td>know, get, good, seem, month, place, report, m...</td>\n",
       "      <td>['true', 'sub', 'community', 'hover', 'certain...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11579</th>\n",
       "      <td>11579</td>\n",
       "      <td>11579</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.3312</td>\n",
       "      <td>people, time, think, make, work, go, much, tes...</td>\n",
       "      <td>['fortunately', 'model', 'ihme', 'capable', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11580</th>\n",
       "      <td>11580</td>\n",
       "      <td>11580</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>case, death, country, need, even, spread, vacc...</td>\n",
       "      <td>['fortunately', 'model', 'ihme', 'capable', 'm...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0  Document_No  Dominant_Topic  Topic_Perc_Contrib  \\\n",
       "11576       11576        11576             2.0              0.3971   \n",
       "11577       11577        11577             0.0              0.3321   \n",
       "11578       11578        11578             3.0              0.4027   \n",
       "11579       11579        11579             2.0              0.3312   \n",
       "11580       11580        11580             0.0              0.3245   \n",
       "\n",
       "                                                Keywords  \\\n",
       "11576  people, time, think, make, work, go, much, tes...   \n",
       "11577  case, death, country, need, even, spread, vacc...   \n",
       "11578  know, get, good, seem, month, place, report, m...   \n",
       "11579  people, time, think, make, work, go, much, tes...   \n",
       "11580  case, death, country, need, even, spread, vacc...   \n",
       "\n",
       "                                                    Text  \n",
       "11576  ['economic', 'analysis', 'economic', 'decision...  \n",
       "11577  ['sub', 'seem', 'attract', 'poster', 'late', '...  \n",
       "11578  ['true', 'sub', 'community', 'hover', 'certain...  \n",
       "11579  ['fortunately', 'model', 'ihme', 'capable', 'm...  \n",
       "11580  ['fortunately', 'model', 'ihme', 'capable', 'm...  "
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_tm.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "74fc80af",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dfs = [r1, r2, r3]\n",
    "reddit = pd.concat(reddit_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "01971820",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit[['Dominant_Topic','Topic_Perc_Contrib','Keywords']] = overall_tm[['Dominant_Topic','Topic_Perc_Contrib','Keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f274c212",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.columns = (reddit.columns.str.replace(' ', '_', regex=True).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "71422a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11581 entries, 0 to 11580\n",
      "Data columns (total 21 columns):\n",
      " #   Column                      Non-Null Count  Dtype  \n",
      "---  ------                      --------------  -----  \n",
      " 0   id                          11581 non-null  object \n",
      " 1   author                      11581 non-null  object \n",
      " 2   title                       11581 non-null  object \n",
      " 3   score                       11581 non-null  int64  \n",
      " 4   comms_num                   11581 non-null  int64  \n",
      " 5   created                     11581 non-null  float64\n",
      " 6   timestamp                   11581 non-null  object \n",
      " 7   commenter                   9901 non-null   object \n",
      " 8   comment                     11557 non-null  object \n",
      " 9   top_lvl                     11581 non-null  int64  \n",
      " 10  sentiment_polarity          11581 non-null  float64\n",
      " 11  sentiment_polarity_summary  11581 non-null  object \n",
      " 12  top_emotion                 11581 non-null  object \n",
      " 13  top_emotion_score           11581 non-null  float64\n",
      " 14  second_emotion              11581 non-null  object \n",
      " 15  second_emotion_score        11581 non-null  float64\n",
      " 16  third_emotion               11581 non-null  object \n",
      " 17  third_emotion_score         11581 non-null  float64\n",
      " 18  dominant_topic              11581 non-null  float64\n",
      " 19  topic_perc_contrib          11581 non-null  float64\n",
      " 20  keywords                    11581 non-null  object \n",
      "dtypes: float64(7), int64(3), object(11)\n",
      "memory usage: 1.9+ MB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9355b590",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.to_json('./reddits_upload.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f99b7862",
   "metadata": {},
   "source": [
    "### Reddit simplified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bacec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = pd.read_csv('../Reddit_Data/Reddit_Coronavirus_Anti-Lockdown_100.csv')\n",
    "r2 = pd.read_csv('../Reddit_Data/Reddit_Coronavirus_Lockdown_100.csv')\n",
    "r3 = pd.read_csv('../Reddit_Data/Reddit_COVID19_Lockdown_100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa0edf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_dfs = [r1, r2, r3]\n",
    "reddit = pd.concat(reddit_dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45ffe91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.drop(columns=['body'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89c00ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 300 entries, 0 to 299\n",
      "Data columns (total 8 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   author     300 non-null    object \n",
      " 1   title      300 non-null    object \n",
      " 2   score      300 non-null    int64  \n",
      " 3   id         300 non-null    object \n",
      " 4   url        300 non-null    object \n",
      " 5   comms_num  300 non-null    int64  \n",
      " 6   created    300 non-null    float64\n",
      " 7   timestamp  300 non-null    object \n",
      "dtypes: float64(1), int64(2), object(5)\n",
      "memory usage: 18.9+ KB\n"
     ]
    }
   ],
   "source": [
    "reddit.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fdccf4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit.to_json('./reddits_upload_simple.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62eb2f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter = pd.read_json('./tweets_upload.json', orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "96c44a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter.to_csv('./tweets.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "24a5c963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11337 entries, 0 to 11336\n",
      "Data columns (total 17 columns):\n",
      " #   Column                Non-Null Count  Dtype              \n",
      "---  ------                --------------  -----              \n",
      " 0   datetime              11337 non-null  datetime64[ns, UTC]\n",
      " 1   tweet_id              11337 non-null  int64              \n",
      " 2   text                  11337 non-null  object             \n",
      " 3   username              11337 non-null  object             \n",
      " 4   sentiment_score       11337 non-null  float64            \n",
      " 5   sentiment_label       11337 non-null  object             \n",
      " 6   rt_username           23 non-null     object             \n",
      " 7   tag_usernames         3617 non-null   object             \n",
      " 8   top_emotion           11337 non-null  object             \n",
      " 9   top_emotion_score     11337 non-null  float64            \n",
      " 10  second_emotion        11337 non-null  object             \n",
      " 11  second_emotion_score  11337 non-null  float64            \n",
      " 12  third_emotion         11337 non-null  object             \n",
      " 13  third_emotion_score   11337 non-null  float64            \n",
      " 14  dominant_topic        11337 non-null  int64              \n",
      " 15  topic_perc_contrib    11337 non-null  float64            \n",
      " 16  keywords              11337 non-null  object             \n",
      "dtypes: datetime64[ns, UTC](1), float64(5), int64(2), object(9)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "twitter.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d21ed746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>dominant_topic</th>\n",
       "      <th>keywords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Coronavirus: Washington state nursing home pla...</td>\n",
       "      <td>2</td>\n",
       "      <td>ncov, put, spread, leave, case, first, quarant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@amybruni @JohnDePetroshow @NewportBuzz Someon...</td>\n",
       "      <td>1</td>\n",
       "      <td>people, day, case, city, town, country, outbre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@luispedrocoelho Here's how the #coronavirus s...</td>\n",
       "      <td>0</td>\n",
       "      <td>week, news, life, post, call, second, force, d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tourists staying at a Tenerife hotel that has ...</td>\n",
       "      <td>2</td>\n",
       "      <td>ncov, put, spread, leave, case, first, quarant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We don't have a clue.\\r\\nOnly thing we saw is ...</td>\n",
       "      <td>2</td>\n",
       "      <td>ncov, put, spread, leave, case, first, quarant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11332</th>\n",
       "      <td>#pinup #pinupstyle #pinupfashion #mermaiddress...</td>\n",
       "      <td>2</td>\n",
       "      <td>right, catch, people, need, case, go, due, say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11333</th>\n",
       "      <td>#pinup #pinupstyle #pinupfashion #mermaiddress...</td>\n",
       "      <td>1</td>\n",
       "      <td>tune, drive, exclusive, skoda, soil, home, hel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11334</th>\n",
       "      <td>@agalbraith I think allowing â€œ sale of non-ess...</td>\n",
       "      <td>3</td>\n",
       "      <td>day, stayhome, total, state, virus, spread, co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11335</th>\n",
       "      <td>@GlobalCalgary Str8 up clowning ðŸ¤¡ and after lo...</td>\n",
       "      <td>2</td>\n",
       "      <td>right, catch, people, need, case, go, due, say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11336</th>\n",
       "      <td>Alcohol consumption is a timely issues as the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>tune, drive, exclusive, skoda, soil, home, hel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11337 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  dominant_topic  \\\n",
       "0      Coronavirus: Washington state nursing home pla...               2   \n",
       "1      @amybruni @JohnDePetroshow @NewportBuzz Someon...               1   \n",
       "2      @luispedrocoelho Here's how the #coronavirus s...               0   \n",
       "3      Tourists staying at a Tenerife hotel that has ...               2   \n",
       "4      We don't have a clue.\\r\\nOnly thing we saw is ...               2   \n",
       "...                                                  ...             ...   \n",
       "11332  #pinup #pinupstyle #pinupfashion #mermaiddress...               2   \n",
       "11333  #pinup #pinupstyle #pinupfashion #mermaiddress...               1   \n",
       "11334  @agalbraith I think allowing â€œ sale of non-ess...               3   \n",
       "11335  @GlobalCalgary Str8 up clowning ðŸ¤¡ and after lo...               2   \n",
       "11336  Alcohol consumption is a timely issues as the ...               1   \n",
       "\n",
       "                                                keywords  \n",
       "0      ncov, put, spread, leave, case, first, quarant...  \n",
       "1      people, day, case, city, town, country, outbre...  \n",
       "2      week, news, life, post, call, second, force, d...  \n",
       "3      ncov, put, spread, leave, case, first, quarant...  \n",
       "4      ncov, put, spread, leave, case, first, quarant...  \n",
       "...                                                  ...  \n",
       "11332  right, catch, people, need, case, go, due, say...  \n",
       "11333  tune, drive, exclusive, skoda, soil, home, hel...  \n",
       "11334  day, stayhome, total, state, virus, spread, co...  \n",
       "11335  right, catch, people, need, case, go, due, say...  \n",
       "11336  tune, drive, exclusive, skoda, soil, home, hel...  \n",
       "\n",
       "[11337 rows x 3 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twitter[['text','dominant_topic','keywords']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8622cc14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
