{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/anaconda3/lib/python3.8/site-packages (23.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: snscrape in /opt/anaconda3/lib/python3.8/site-packages (0.6.2.20230320)\n",
      "Requirement already satisfied: pytz in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (2020.1)\n",
      "Requirement already satisfied: lxml in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.5.2)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (3.0.12)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (4.8.2)\n",
      "Requirement already satisfied: requests[socks] in /opt/anaconda3/lib/python3.8/site-packages (from snscrape) (2.24.0)\n",
      "Requirement already satisfied: soupsieve>=1.2 in /opt/anaconda3/lib/python3.8/site-packages (from beautifulsoup4->snscrape) (2.0.1)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (2022.12.7)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (3.0.4)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/anaconda3/lib/python3.8/site-packages (from requests[socks]->snscrape) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade snscrape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-e01019e7501c>:19: DeprecatedFeatureWarning: content is deprecated, use rawContent instead\n",
      "  tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.coordinates, tweet.place])\n"
     ]
    }
   ],
   "source": [
    "# since:2020-03-16 until:2020-03-30 - Mar\n",
    "# since:2020-01-27 until:2020-03-02 - Jan_Mar\n",
    "# since:2020-04-27 until:2020-11-30 - May_Nov\n",
    "# China Data:\n",
    "# since:2020-01-23 until:2020-04-08 - Jan_Apr_2020\n",
    "# since:2022-04-01 until:2022-06-01 - May_June_2022\n",
    "\n",
    "# Creating list to append tweet data \n",
    "tweets_list = []\n",
    "\n",
    "# search terms (covid19 lockdown)\n",
    "search_terms = '疫情 封城'\n",
    "\n",
    "# Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "for i, tweet in enumerate(sntwitter.TwitterSearchScraper(search_terms + ' since:2022-04-01 until:2022-06-01').get_items()):\n",
    "    if i > 5000:\n",
    "        break\n",
    "    # declare the attributes to be returned\n",
    "    tweets_list.append([tweet.date, tweet.id, tweet.content, tweet.user.username, tweet.coordinates, tweet.place])\n",
    "\n",
    "# Creating a dataframe from the tweets list above\n",
    "tweets_df = pd.DataFrame(tweets_list, columns=['Datetime', 'Tweet Id', 'Text', 'Username', 'Coordinates', 'Place'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retweets = tweets_df['Text']\n",
    "# retweets\n",
    "for text in retweets:\n",
    "    if 'RT' in text:\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to a CSV\n",
    "\n",
    "path = \"./Twitter_Data_Chinese/\"\n",
    "if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "tweets_df.to_csv('./Twitter_Data_Chinese/Twitter_May_June_2022_5000_chinese.csv', index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
